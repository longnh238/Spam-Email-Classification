{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":213216,"sourceType":"datasetVersion","datasetId":91827},{"sourceId":998616,"sourceType":"datasetVersion","datasetId":547699}],"dockerImageVersionId":30761,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Spam Email Classification\n","metadata":{}},{"cell_type":"markdown","source":"## Introduction\n- The proliferation of email as a primary communication tool has brought about significant convenience and challenges, such as the issue of spam emails. Spam emails not only clutter inboxes but also pose security risks by potentially containing malicious content.\n- Therefore, effectively classifying emails as spam or non-spam is critical for enhancing user experience and maintaining cybersecurity. \nThis notebook aims to classify emails into spam and non-spam categories using data analysis and machine learning technique.\n- This notebook details the methodology, analysis, and conclusions drawn from the project. It covers the data preprocessing steps, visualizati n techniques used, and the statistical analysis conducted. Additionally, it discusses the challenges encountered and the solutions implemented to address they.\r\n","metadata":{}},{"cell_type":"markdown","source":"## Methodology\n\nThe notebook followed a structured approach consisting of the following steps:\n- Data Collection and Preparation: Gather and prepare the data for analysis.\n- Exploratory Data Analysis: Investigate data to find patterns, spot anomalies, and check assumptions using summary statistics and graphs.\n- Feature Engineering: Create relevant features from the data.\n- Model Development: Develop and train various machine learning models.\n- Model Evaluation: Assess the performance of the models using various metrics.\n- External Validation: Test the final model on new data to ensure its robustness and generalizability.\n\nThe detail of each step is given below.","metadata":{}},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"## A. Import Libraries","metadata":{}},{"cell_type":"markdown","source":"- Importing essential libraries needed for data analysis, visualization, and machine learning tasks. It imports numpy and pandas, which are fundamental for handling numerical data and data frames, respectively.\n- For visualization, matplotlib.pyplot and seaborn are imported, providing tools for creating a wide range of static, animated, and interactive plots.\n- The train_test_split function from the sklearn.model_selection module is brought in to facilitate the division of the dataset into training and testing subsets, crucial for model evaluation.\n- Lastly, the code imports classification_report and confusion_matrix from sklearn.metrics, which are used to assess the performance of classification models by generating detailed reports and confusion matrices, respectively.","metadata":{}},{"cell_type":"code","source":"# Import necessary libraries for data analysis and visualization\nimport numpy as np  \nimport pandas as pd  \n\n# Import libraries for plotting and visualization\nimport matplotlib.pyplot as plt  \nimport seaborn as sb  \n\n# Import train_test_split function for splitting data into training and test sets\nfrom sklearn.model_selection import train_test_split\n\n# Importing necessary functions for evaluating classification performance\nfrom sklearn.metrics import classification_report, confusion_matrix","metadata":{"execution":{"iopub.status.busy":"2024-08-23T13:02:28.290733Z","iopub.execute_input":"2024-08-23T13:02:28.291159Z","iopub.status.idle":"2024-08-23T13:02:29.403228Z","shell.execute_reply.started":"2024-08-23T13:02:28.291119Z","shell.execute_reply":"2024-08-23T13:02:29.402083Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Importing the Natural Language Toolkit (nltk) library, which is widely used for various natural language processing (NLP) tasks.\n- Specifically, it imports the stopwords module from nltk.corpus, which provides a collection of common stop words that can be filtered out during text processing to improve the efficiency of NLP tasks.","metadata":{}},{"cell_type":"code","source":"# Import the Natural Language Toolkit (nltk) library for natural language processing tasks\nimport nltk\nfrom nltk.corpus import stopwords  # Import the stopwords module to work with common stop words\n\n# Download the stopwords dataset from nltk\nnltk.download(\"stopwords\")","metadata":{"execution":{"iopub.status.busy":"2024-08-23T13:02:29.405154Z","iopub.execute_input":"2024-08-23T13:02:29.405677Z","iopub.status.idle":"2024-08-23T13:02:49.674269Z","shell.execute_reply.started":"2024-08-23T13:02:29.405636Z","shell.execute_reply":"2024-08-23T13:02:49.673081Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"## B. Data Collection and Preparation\n\n- At first, load the dataset into a DataFrame using the Pandas library in Python. This is the first step in data exploration and preprocessing. It enables us to perform various operations, such as cleaning, transforming, and analyzing the data.","metadata":{}},{"cell_type":"code","source":"# Import dataset \ndf = pd.read_csv(\"/kaggle/input/email-spam-classification-dataset-csv/emails.csv\", index_col=0)\ndf","metadata":{"execution":{"iopub.status.busy":"2024-08-23T13:02:49.675711Z","iopub.execute_input":"2024-08-23T13:02:49.676149Z","iopub.status.idle":"2024-08-23T13:02:51.165139Z","shell.execute_reply.started":"2024-08-23T13:02:49.676109Z","shell.execute_reply":"2024-08-23T13:02:51.163815Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"## C. Exploratory Data Analysis\n\n- Afterward, checked the structure and missing values to prepare the data for further processing and modeling. Besides, calculate descriptive statistics to give a summary of the data and help in understanding its characteristics. They are useful for identifying trends, outliers, and the overall distribution of the data.","metadata":{}},{"cell_type":"markdown","source":"### 1. DataFrame Inspection\n\n- Upon loading the dataset into a DataFrame, it is important to review its structure. This includes checking the column names to understand what features are present, verifying data types (e.g., numeric, categorical, text), and inspecting a sample of data entries to get an initial sense of the data. ","metadata":{}},{"cell_type":"markdown","source":"#### a. Display the First 10 Rows of the DataFrame\n\n- The head method provides a quick overview of the dataset, showing the initial rows along with the column names and some of the data contained within.","metadata":{}},{"cell_type":"code","source":"df.head(10)","metadata":{"execution":{"iopub.status.busy":"2024-08-23T13:02:51.167693Z","iopub.execute_input":"2024-08-23T13:02:51.168055Z","iopub.status.idle":"2024-08-23T13:02:51.188175Z","shell.execute_reply.started":"2024-08-23T13:02:51.168017Z","shell.execute_reply":"2024-08-23T13:02:51.186903Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### b. Display the Last 10 Rows of the DataFrame\n\n- The tail method provides a quick look at the end of the dataset, showing the final rows along with the column names and some of the data contained within.","metadata":{}},{"cell_type":"code","source":"df.tail(10)","metadata":{"execution":{"iopub.status.busy":"2024-08-23T13:02:51.189600Z","iopub.execute_input":"2024-08-23T13:02:51.190009Z","iopub.status.idle":"2024-08-23T13:02:51.213253Z","shell.execute_reply.started":"2024-08-23T13:02:51.189947Z","shell.execute_reply":"2024-08-23T13:02:51.211945Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### c. Checking Shape\n\n- The df.shape returns a tuple representing the dimensions of the DataFrame.\n- The first element of the tuple indicates the number of rows, and the second element indicates the number of columns.","metadata":{}},{"cell_type":"code","source":"df.shape","metadata":{"execution":{"iopub.status.busy":"2024-08-23T13:02:51.214777Z","iopub.execute_input":"2024-08-23T13:02:51.215167Z","iopub.status.idle":"2024-08-23T13:02:51.225928Z","shell.execute_reply.started":"2024-08-23T13:02:51.215126Z","shell.execute_reply":"2024-08-23T13:02:51.224806Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### d. List of Columns\n\n- The df.columns returns an Index object containing the column labels of the DataFrame.\n- This allows us to see the names of all the columns. ","metadata":{}},{"cell_type":"code","source":"df.columns","metadata":{"execution":{"iopub.status.busy":"2024-08-23T13:02:51.227421Z","iopub.execute_input":"2024-08-23T13:02:51.227784Z","iopub.status.idle":"2024-08-23T13:02:51.240546Z","shell.execute_reply.started":"2024-08-23T13:02:51.227748Z","shell.execute_reply":"2024-08-23T13:02:51.239346Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### e. Data Types of Each Feature\n\n- The df.dtypes attribute returns a Series with the data type of each column in the DataFrame.\n- This is useful for understanding the types of data we are working with, such as integers, floats, strings, or more complex types.\n- Knowing the data types helps in performing appropriate data processing and analysis tasks, as certain operations are only applicable to specific data types.","metadata":{}},{"cell_type":"code","source":"df.dtypes","metadata":{"execution":{"iopub.status.busy":"2024-08-23T13:02:51.241668Z","iopub.execute_input":"2024-08-23T13:02:51.241992Z","iopub.status.idle":"2024-08-23T13:02:51.255408Z","shell.execute_reply.started":"2024-08-23T13:02:51.241959Z","shell.execute_reply":"2024-08-23T13:02:51.254174Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### f. Information Summary\n\n- The df.info() provides a concise summary of the DataFrame's structure including the total number of entries (rows), the number of non-null values in each column, the data type of each column, and the memory usage of the DataFrame.","metadata":{}},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2024-08-23T13:02:51.256762Z","iopub.execute_input":"2024-08-23T13:02:51.257190Z","iopub.status.idle":"2024-08-23T13:02:51.467958Z","shell.execute_reply.started":"2024-08-23T13:02:51.257150Z","shell.execute_reply":"2024-08-23T13:02:51.466703Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Observation after DataFrame Inspection\n\n- By observing the dataset, see that it consists of 5172 emails represented as rows, where each email's features are counts of the 3000 most common words.\n- This creates a high-dimensional feature space with sparse data, typical in text classification tasks.","metadata":{}},{"cell_type":"markdown","source":"### 2. Summary of DataFrame Statistics\n\n- Generating descriptive statistics provides insights into the data’s central tendencies and variability.\n- Because this dataset contains only numerical features, calculated the mean, median, standard deviation, and range.\n- These statistics help in identifying patterns and potential anomalies in the data.","metadata":{}},{"cell_type":"code","source":"df.describe()","metadata":{"execution":{"iopub.status.busy":"2024-08-23T13:02:51.471605Z","iopub.execute_input":"2024-08-23T13:02:51.471943Z","iopub.status.idle":"2024-08-23T13:02:56.447762Z","shell.execute_reply.started":"2024-08-23T13:02:51.471908Z","shell.execute_reply":"2024-08-23T13:02:56.446609Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- The features show significant variation, with high mean values for common words, substantial standard deviations, and a wide range of minimum and maximum values.\n- Quartile statistics reveal that many features have low occurrence rates for a large portion of the data, with the median and 75th percentile providing insights into data distribution and spread.\n- From the summary statistics, see the high standard deviations and diverse range of minimum and maximum values highlight the richness and complexity of text data.","metadata":{}},{"cell_type":"markdown","source":"### 3. Checking Null Values\n- Identifying and handling missing values is a crucial step.\n- Missing values can arise from various sources and can lead to biased or inaccurate model predictions if not addressed.","metadata":{}},{"cell_type":"code","source":"df.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2024-08-23T13:02:56.449205Z","iopub.execute_input":"2024-08-23T13:02:56.449721Z","iopub.status.idle":"2024-08-23T13:02:56.472294Z","shell.execute_reply.started":"2024-08-23T13:02:56.449672Z","shell.execute_reply":"2024-08-23T13:02:56.470816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- This indicates no missing (null) values in any of the columns.\n- This means that the dataset is complete and there are no entries that need to be handled or imputed due to missing data.","metadata":{}},{"cell_type":"markdown","source":"### 4. Label Distribution\n\n- Count of occurrences for each category in the 'Prediction' column\n- Analyzing the distribution of the target labels (spam vs. non-spam) helps understand the balance of the dataset.","metadata":{}},{"cell_type":"code","source":"# Count the number of occurrences of each value in the 'Prediction' column\ndf['Prediction'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2024-08-23T13:02:56.473755Z","iopub.execute_input":"2024-08-23T13:02:56.474730Z","iopub.status.idle":"2024-08-23T13:02:56.485689Z","shell.execute_reply.started":"2024-08-23T13:02:56.474671Z","shell.execute_reply":"2024-08-23T13:02:56.484619Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a new figure with a specified size\nplt.figure(figsize=(4, 2))\n\n# Create a count plot using Seaborn to show the count of occurrences for each category in the 'Prediction' column\nsb.countplot(x = 'Prediction',\n            data = df)\nplt.xticks([0,1],['Not Spam','Spam'])\n\n# Display the plot\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-08-23T13:02:56.487076Z","iopub.execute_input":"2024-08-23T13:02:56.487459Z","iopub.status.idle":"2024-08-23T13:02:56.684921Z","shell.execute_reply.started":"2024-08-23T13:02:56.487413Z","shell.execute_reply":"2024-08-23T13:02:56.684058Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Observation after Checking Label Distribution\n- Oserved that the dataset is imbalanced, meaning there are significantly more non-spam emails than spam ones.\n- This imbalance can affect the performance of classification algorithms, as they might be biased towards the majority class (non-spam).","metadata":{}},{"cell_type":"markdown","source":"### 5. Create Distribution Plots for the First 12 Columns\n\n- Generates distribution plots (histograms with Kernel Density Estimate overlays) for the first 12 columns\n- This allows us to visually inspect how the values of each feature are distributed across non-spam and spam emails.","metadata":{}},{"cell_type":"code","source":"# Number of columns to plot\nnum_columns = 12\n\n# Create a figure and axes\nfig, axes = plt.subplots(nrows=4, ncols=3, figsize=(12, 12))\n\n# Flatten the axes array for easy iteration\naxes = axes.flatten()\n\n# Filter data based on spam and non-spam\nspam_df = df[df['Prediction'] == 1]\nnon_spam_df = df[df['Prediction'] == 0]\n\n# Loop through the first 12 columns and create distribution plots for spam and non-spam\nfor i, col in enumerate(df.columns[:num_columns]):\n    # Plot for non-spam emails\n    sb.histplot(non_spam_df[col], ax=axes[i], kde=True, color='blue', label='Non-Spam')\n    # Plot for spam emails\n    sb.histplot(spam_df[col], ax=axes[i], kde=True, color='red', label='Spam')\n    axes[i].set_title(col)\n    axes[i].legend()\n\n# Adjust the layout\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-08-23T13:02:56.686051Z","iopub.execute_input":"2024-08-23T13:02:56.686566Z","iopub.status.idle":"2024-08-23T13:03:10.202427Z","shell.execute_reply.started":"2024-08-23T13:02:56.686529Z","shell.execute_reply":"2024-08-23T13:03:10.201310Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Overall, these histograms illustrate that common words such as \"the\", \"to\", \"etc\", \"and,\" \"for,\" \"of,\" \"a,\" \"you,\" \"in,\" \"on,\" and \"is\" appear more frequently in non-spam emails than in spam emails. However, the difference in word frequency distributions between spam and non-spam emails could be influenced by the prediction counts.","metadata":{}},{"cell_type":"markdown","source":"### 6. The Correlation Matrix for the Numeric Columns\n\n- Visualizing the pairwise correlations between numeric features in the dataset.\n- By plotting the heatmap, can easily identify strong and weak correlations, patterns, and relationships among features.","metadata":{}},{"cell_type":"code","source":"# Calculate the correlation matrix for the numeric columns in the dataset.\ncorrelation_matrix = df.corr()\n\n# Build a matrix of booleans (True, False) with the same shape as the data\nones_corr = np.ones_like(correlation_matrix, dtype=bool)\n\n# The variable mask now contains the upper triangular matrix mask created in the previous step\nmask = np.triu(ones_corr)\n\n# Create a heatmap to visualize the correlation matrix.\nsb.heatmap(correlation_matrix, mask=mask, annot=False, cmap=\"coolwarm\")\n\n# Customize the plot\nplt.title(\"Correlation Heatmap\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-08-23T13:03:10.203797Z","iopub.execute_input":"2024-08-23T13:03:10.204777Z","iopub.status.idle":"2024-08-23T13:05:24.981709Z","shell.execute_reply.started":"2024-08-23T13:03:10.204722Z","shell.execute_reply":"2024-08-23T13:05:24.980552Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- The heatmap shows that most word pairs have very low or no correlation, as indicated by the predominance of blue and white colors.\n- There are a few small red and blue dots scattered, which indicate some word pairs have a noticeable positive or negative correlation, but these are relatively rare.","metadata":{}},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"## D. Data Modelling\n\n- Begin by applying a simple model to evaluate the performance of the data.\n- This initial step involves using basic machine learning algorithms to establish a baseline for model performance.\n- By assessing how well these simple models perform, can evaluate the effectiveness of the data and identify potential areas for improvement.\n- This baseline also allows us to compare more complex models and techniques, ensuring that any advancements in performance are meaningful and not just a result of overfitting or data leakage.","metadata":{}},{"cell_type":"markdown","source":"### 1. Train-Test Sets Preparation","metadata":{}},{"cell_type":"markdown","source":"#### a. Create a New DataFrame X by Dropping the 'Prediction' Column from the Original DataFrame","metadata":{}},{"cell_type":"code","source":"X = df.drop(\"Prediction\", axis=1)\nX","metadata":{"execution":{"iopub.status.busy":"2024-08-23T13:05:24.983117Z","iopub.execute_input":"2024-08-23T13:05:24.983485Z","iopub.status.idle":"2024-08-23T13:05:25.043663Z","shell.execute_reply.started":"2024-08-23T13:05:24.983448Z","shell.execute_reply":"2024-08-23T13:05:25.042585Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### b. Extract the 'Prediction' Column From the Original DataFrame and Store It in a New Variable y","metadata":{}},{"cell_type":"code","source":"y = df[\"Prediction\"]\ny","metadata":{"execution":{"iopub.status.busy":"2024-08-23T13:05:25.045106Z","iopub.execute_input":"2024-08-23T13:05:25.045497Z","iopub.status.idle":"2024-08-23T13:05:25.054104Z","shell.execute_reply.started":"2024-08-23T13:05:25.045459Z","shell.execute_reply":"2024-08-23T13:05:25.052936Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### c. Split the Data Into Training and Test Sets","metadata":{}},{"cell_type":"code","source":"# Split the data into training and test sets\n   # X_train and y_train are the training sets\n   # X_test and y_test are the test sets\n# test_size=0.2 means 20% of the data will be used for testing and 80% for training\n# random_state=42 ensures reproducibility of the split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Display the shapes of the resulting training and test sets\nprint(f\"Training Features Shape: {X_train.shape}\")\nprint(f\"Training Labels Shape: {y_train.shape}\")\nprint(f\"Test Features Shape: {X_test.shape}\")\nprint(f\"Test Labels Shape: {y_test.shape}\")","metadata":{"execution":{"iopub.status.busy":"2024-08-23T13:05:25.055570Z","iopub.execute_input":"2024-08-23T13:05:25.056020Z","iopub.status.idle":"2024-08-23T13:05:25.149769Z","shell.execute_reply.started":"2024-08-23T13:05:25.055972Z","shell.execute_reply":"2024-08-23T13:05:25.148440Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Determine the number of features (columns) in the DataFrame X\n# Determine the unique classes in the Series y and assign it to n_classes\nn_features, n_classes = X.shape[1], np.unique(y)\n\n# Display the number of features and the unique classes\nn_features, n_classes","metadata":{"execution":{"iopub.status.busy":"2024-08-23T13:05:25.151166Z","iopub.execute_input":"2024-08-23T13:05:25.151628Z","iopub.status.idle":"2024-08-23T13:05:25.159597Z","shell.execute_reply.started":"2024-08-23T13:05:25.151587Z","shell.execute_reply":"2024-08-23T13:05:25.158382Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 2. Apply Multinomial Naive Bayes\n\n- At first, apply the Naive Bayes algorithm because it is well-suited for text classification tasks, where each email is represented by word counts (or frequencies) of the most common words. \n- MultinomialNB is chosen because it works with features that represent counts, which aligns with the dataset structure where each cell represents the count of a specific word in an email. \n- Besides, MultinomialNB naturally supports binary classification tasks, where the goal is to predict whether an email is spam (1) or not spam (0)","metadata":{}},{"cell_type":"code","source":"# Importing the Multinomial Naive Bayes classifier from scikit-learn\nfrom sklearn.naive_bayes import MultinomialNB","metadata":{"execution":{"iopub.status.busy":"2024-08-23T13:05:25.161065Z","iopub.execute_input":"2024-08-23T13:05:25.161421Z","iopub.status.idle":"2024-08-23T13:05:25.177107Z","shell.execute_reply.started":"2024-08-23T13:05:25.161379Z","shell.execute_reply":"2024-08-23T13:05:25.175797Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Instantiate a Multinomial Naive Bayes classifier\nnb = MultinomialNB()\n\n# Train (fit) the classifier on the training data\nnb.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2024-08-23T13:05:25.178615Z","iopub.execute_input":"2024-08-23T13:05:25.179356Z","iopub.status.idle":"2024-08-23T13:05:25.271557Z","shell.execute_reply.started":"2024-08-23T13:05:25.179303Z","shell.execute_reply":"2024-08-23T13:05:25.270441Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Use the trained Naive Bayes classifier to predict the labels of the test data\ny_pred_nb = nb.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2024-08-23T13:05:25.272720Z","iopub.execute_input":"2024-08-23T13:05:25.273037Z","iopub.status.idle":"2024-08-23T13:05:25.345130Z","shell.execute_reply.started":"2024-08-23T13:05:25.272998Z","shell.execute_reply":"2024-08-23T13:05:25.343845Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Print the classification report, which includes precision, recall, F1-score, and support for each class\nprint(\"Classification report: \")\nprint(classification_report(y_test, y_pred_nb))","metadata":{"execution":{"iopub.status.busy":"2024-08-23T13:05:25.346357Z","iopub.execute_input":"2024-08-23T13:05:25.347109Z","iopub.status.idle":"2024-08-23T13:05:25.371021Z","shell.execute_reply.started":"2024-08-23T13:05:25.347060Z","shell.execute_reply":"2024-08-23T13:05:25.369777Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Explanation of Each Metric Result When Applying Multinomial Naive Bayes\n\n- Precision: This measures the accuracy of positive predictions made by the model. For class 0 (not spam), the precision is 0.98, indicating that 98% of emails predicted as not spam were actually not spam. For class 1 (spam), the precision is 0.89, meaning that 89% of emails predicted as spam were actually spam.\n- Recall: It measures the proportion of actual positives that were correctly identified by the model. For class 0, the recall is 0.95, indicating that 95% of actual not spam emails were correctly identified as not spam. For class 1, the recall is 0.96, meaning that 96% of actual spam emails were correctly identified as spam.\n- F1-score: The F1-score is the harmonic mean of precision and recall, providing a single metric that balances both precision and recall. The F1-score for class 0 is 0.97, and for class 1, it is 0.92.\n- Support: Support is the number of actual occurrences of each class in the test dataset. In this case, there are 739 instances of class 0 (not spam) and 296 instances of class 1 (spam).\n- Accuracy: Accuracy measures the overall correctness of the model's predictions across all classes. Here, the overall accuracy is 0.95, meaning that the model correctly predicted 95% of the emails in the test set.","metadata":{}},{"cell_type":"code","source":"# Compute the confusion matrix to evaluate the performance of the Naive Bayes classifier\ncm_nb = confusion_matrix(y_test, y_pred_nb)\n\n# Create a DataFrame from the confusion matrix with labels for rows and columns\ndf_cm_nb = pd.DataFrame(cm_nb, columns=np.unique(y_test), index=np.unique(y_test))\n\n# Set the names for the index (rows) and columns of the DataFrame\ndf_cm_nb.index.name = 'Actual'\ndf_cm_nb.columns.name = 'Predicted'\n\n# Create a new figure for the heatmap with a specific size\nplt.figure(figsize=(1.5, 1.5))\n\n# Generate a heatmap visualization of the confusion matrix\nsb.heatmap(df_cm_nb, annot=True, annot_kws={\"size\": 12}, cbar=False, square=True, fmt=\"d\", cmap=\"Reds\")\n\n# Display the heatmap\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-08-23T13:05:25.373009Z","iopub.execute_input":"2024-08-23T13:05:25.373537Z","iopub.status.idle":"2024-08-23T13:05:25.516582Z","shell.execute_reply.started":"2024-08-23T13:05:25.373485Z","shell.execute_reply":"2024-08-23T13:05:25.515428Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Discussion of Applying Multinomial Naive Bayes\n\n- By observing the confusion matrix, find that reducing false positives for class 1 (spam) predictions is necessary. \n- Multinomial Naive Bayes was initially chosen because it is well-suited for text classification tasks where features (word counts or frequencies) are non-negative integers. Given the class, it assumes that features are conditionally independent, which can work reasonably well for word count data.","metadata":{}},{"cell_type":"markdown","source":"### 3. Apply Logistic Regression\n\n- Then apply the Logistic Regression because Logistic Regression can capture more complex relationships between features and the target variable compared to the assumption of independence in Multinomial Naive Bayes.\n- Multinomial Naive Bayes assumes that features (word counts) are conditionally independent given the class label (spam or not spam). This means that the presence of one word is independent of the presence of other words, which is often not true in real-world text data because the occurrence of words in emails could be correlated or have complex interactions that Logistic Regression can potentially model more accurately.\n- Logistic Regression, on the other hand, models the relationship between the features (word counts) and the probability of each class (spam or not spam) using a logistic function.","metadata":{}},{"cell_type":"code","source":"# Importing the Logistic Regression model from the scikit-learn library.\nfrom sklearn.linear_model import LogisticRegression","metadata":{"execution":{"iopub.status.busy":"2024-08-23T13:05:25.518395Z","iopub.execute_input":"2024-08-23T13:05:25.519151Z","iopub.status.idle":"2024-08-23T13:05:25.524599Z","shell.execute_reply.started":"2024-08-23T13:05:25.519095Z","shell.execute_reply":"2024-08-23T13:05:25.523235Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Initializing the Logistic Regression model with a fixed random state for reproducibility\n# The max_iter parameter is set to 1000 to ensure the solver has sufficient iterations to converge\nreg_log = LogisticRegression(random_state=42, max_iter=1000)\n\n# Training the Logistic Regression model on the training data (X_train and y_train)\nreg_log.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2024-08-23T13:05:25.526497Z","iopub.execute_input":"2024-08-23T13:05:25.527354Z","iopub.status.idle":"2024-08-23T13:05:36.839533Z","shell.execute_reply.started":"2024-08-23T13:05:25.527286Z","shell.execute_reply":"2024-08-23T13:05:36.838334Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Predict the labels for the test data using the trained Logistic Regression model\ny_pred_reg_log = reg_log.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2024-08-23T13:05:36.844726Z","iopub.execute_input":"2024-08-23T13:05:36.845640Z","iopub.status.idle":"2024-08-23T13:05:36.954834Z","shell.execute_reply.started":"2024-08-23T13:05:36.845578Z","shell.execute_reply":"2024-08-23T13:05:36.953619Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Print the classification report to evaluate the performance of the Logistic Regression model\nprint(\"Classification report: \")\nprint(classification_report(y_test, y_pred_reg_log))","metadata":{"execution":{"iopub.status.busy":"2024-08-23T13:05:36.968710Z","iopub.execute_input":"2024-08-23T13:05:36.972684Z","iopub.status.idle":"2024-08-23T13:05:36.998750Z","shell.execute_reply.started":"2024-08-23T13:05:36.972606Z","shell.execute_reply":"2024-08-23T13:05:36.997606Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Compute the confusion matrix to evaluate the performance of the Logistic Regression model\ncm_reg_log = confusion_matrix(y_test, y_pred_reg_log)\n\n# Create a DataFrame for the confusion matrix with appropriate labels for rows and columns\ndf_cm_reg_log = pd.DataFrame(cm_reg_log, columns=np.unique(y_test), index = np.unique(y_test))\n\n# Set names for the index (rows) and columns of the DataFrame\ndf_cm_reg_log.index.name = 'Actual'\ndf_cm_reg_log.columns.name = 'Predicted'\n\n# Create a new figure for the heatmap with specified dimensions\nplt.figure(figsize = (1.5,1.5))\n\n# Generate a heatmap for the confusion matrix with annotations and custom formatting\nsb.heatmap(df_cm_reg_log, annot=True, annot_kws={\"size\": 12}, cbar=False, square=True, fmt=\"d\", cmap=\"Reds\")\n\n# Display the heatmap\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-08-23T13:05:37.003777Z","iopub.execute_input":"2024-08-23T13:05:37.007463Z","iopub.status.idle":"2024-08-23T13:05:37.149640Z","shell.execute_reply.started":"2024-08-23T13:05:37.007394Z","shell.execute_reply":"2024-08-23T13:05:37.148458Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 4. Comparison of Two Models: Multinomial Naive Bayes and Logistic Regression\n\n- Accuracy: Logistic Regression has a higher accuracy (0.97) than Multinomial Naive Bayes (0.95).\n- Precision: For Class 0, both models have a high precision of 0.98. For Class 1, Logistic Regression (0.94) has higher precision than Multinomial Naive Bayes (0.89).\n- Recall: For Class 0, Logistic Regression has a slightly better recall (0.98) than Multinomial Naive Bayes (0.95).\n- F1-Score: Logistic Regression has a better f1-score for both classes, particularly for Class 1 (0.95 vs. 0.92).\n\nTherefore, Logistic Regression performs better than MultinomialNB across most metrics, particularly regarding precision and f1-score for Class 1, which suggests it handles the positive class better.","metadata":{}},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"## E. Improve the Performance of the Logistic Regression Model by Feature Engineering","metadata":{}},{"cell_type":"markdown","source":"### 1. Remove Stop Words\n\n- Stop words are common words that appear frequently in a text but carry little meaningful information, such as \"the,\" \"is,\" \"in,\" \"and,\" etc.\n- Removing these words can improve the performance of machine learning models by reducing noise and dimensionality, leading to more meaningful feature representation and potentially better classification results.","metadata":{}},{"cell_type":"code","source":"# Import the list of stop words from the NLTK library\nstop_words = list(stopwords.words('english'))\n\n# Print the list of stop words\nprint(stop_words)","metadata":{"execution":{"iopub.status.busy":"2024-08-23T13:05:37.151459Z","iopub.execute_input":"2024-08-23T13:05:37.152205Z","iopub.status.idle":"2024-08-23T13:05:37.167056Z","shell.execute_reply.started":"2024-08-23T13:05:37.152153Z","shell.execute_reply":"2024-08-23T13:05:37.164605Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Remove the stop words columns from the DataFrame\n# The 'errors=\"ignore\"' parameter ensures that non-existent columns are ignored\ndf_filtered_sw = df.drop(stop_words, axis=1, errors=\"ignore\")\n\n# Display the resulting DataFrame after stop words removal\ndf_filtered_sw","metadata":{"execution":{"iopub.status.busy":"2024-08-23T13:05:37.168945Z","iopub.execute_input":"2024-08-23T13:05:37.169701Z","iopub.status.idle":"2024-08-23T13:05:37.232443Z","shell.execute_reply.started":"2024-08-23T13:05:37.169645Z","shell.execute_reply":"2024-08-23T13:05:37.231212Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a new DataFrame X_filtered_sw by dropping the 'Prediction' column from df_filtered_sw\nX_filtered_sw = df_filtered_sw.drop(\"Prediction\", axis=1)\n\n# Display X_filtered_sw, which now contains the filtered features after stop words removal\nX_filtered_sw","metadata":{"execution":{"iopub.status.busy":"2024-08-23T13:05:37.234040Z","iopub.execute_input":"2024-08-23T13:05:37.234444Z","iopub.status.idle":"2024-08-23T13:05:37.303322Z","shell.execute_reply.started":"2024-08-23T13:05:37.234405Z","shell.execute_reply":"2024-08-23T13:05:37.302162Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a new Series y_filtered_sw containing the 'Prediction' column from df_filtered_sw\ny_filtered_sw = df_filtered_sw[\"Prediction\"]\n\n# Display y_filtered_sw, which now contains the labels after stop words removal\ny_filtered_sw","metadata":{"execution":{"iopub.status.busy":"2024-08-23T13:05:37.304841Z","iopub.execute_input":"2024-08-23T13:05:37.305295Z","iopub.status.idle":"2024-08-23T13:05:37.314637Z","shell.execute_reply.started":"2024-08-23T13:05:37.305243Z","shell.execute_reply":"2024-08-23T13:05:37.313571Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Split the Filtered Dataset Into Training and Testing Sets","metadata":{}},{"cell_type":"code","source":"X_train_filtered_sw, X_test_filtered_sw, y_train_filtered_sw, y_test_filtered_sw = train_test_split(X_filtered_sw, y_filtered_sw, test_size=0.2, random_state=42)\n\n# Print the shapes of the training and testing sets to verify the split\nprint(X_train_filtered_sw.shape, y_train_filtered_sw.shape, X_test_filtered_sw.shape, y_test_filtered_sw.shape)","metadata":{"execution":{"iopub.status.busy":"2024-08-23T13:05:37.316032Z","iopub.execute_input":"2024-08-23T13:05:37.316575Z","iopub.status.idle":"2024-08-23T13:05:37.411271Z","shell.execute_reply.started":"2024-08-23T13:05:37.316531Z","shell.execute_reply":"2024-08-23T13:05:37.409940Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Apply Logistic Regression","metadata":{}},{"cell_type":"code","source":"# Initialize a Logistic Regression model with specified random state and maximum iterations\nreg_log_filtered_sw = LogisticRegression(random_state=42, max_iter=1000)\n\n# Train the Logistic Regression model on the filtered training data\nreg_log_filtered_sw.fit(X_train_filtered_sw, y_train_filtered_sw)","metadata":{"execution":{"iopub.status.busy":"2024-08-23T13:05:37.412609Z","iopub.execute_input":"2024-08-23T13:05:37.412952Z","iopub.status.idle":"2024-08-23T13:05:44.159164Z","shell.execute_reply.started":"2024-08-23T13:05:37.412916Z","shell.execute_reply":"2024-08-23T13:05:44.158030Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Predict the labels for the filtered test data using the trained Logistic Regression model\ny_pred_reg_log_filtered_sw = reg_log_filtered_sw.predict(X_test_filtered_sw)","metadata":{"execution":{"iopub.status.busy":"2024-08-23T13:05:44.164136Z","iopub.execute_input":"2024-08-23T13:05:44.167553Z","iopub.status.idle":"2024-08-23T13:05:44.270918Z","shell.execute_reply.started":"2024-08-23T13:05:44.167483Z","shell.execute_reply":"2024-08-23T13:05:44.269729Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Print a header for the classification report\nprint(\"Classification report: \")\n\n# Print the classification report to evaluate the performance of the Logistic Regression model\nprint(classification_report(y_test_filtered_sw, y_pred_reg_log_filtered_sw))","metadata":{"execution":{"iopub.status.busy":"2024-08-23T13:05:44.276326Z","iopub.execute_input":"2024-08-23T13:05:44.277236Z","iopub.status.idle":"2024-08-23T13:05:44.308639Z","shell.execute_reply.started":"2024-08-23T13:05:44.277174Z","shell.execute_reply":"2024-08-23T13:05:44.307435Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Compute the confusion matrix to evaluate the performance of the Logistic Regression model\ncm_reg_log_filtered_sw = confusion_matrix(y_test_filtered_sw, y_pred_reg_log_filtered_sw)\n\ndf_cm_reg_log_filtered_sw = pd.DataFrame(cm_reg_log_filtered_sw, columns=np.unique(y_test), index = np.unique(y_test))\n\n# Set the names for the DataFrame's index (rows) and columns\ndf_cm_reg_log_filtered_sw.index.name = 'Actual'\ndf_cm_reg_log_filtered_sw.columns.name = 'Predicted'\n\n# Create a new figure for the heatmap \nplt.figure(figsize = (1.5,1.5))\n\n# Generate the heatmap visualization\nsb.heatmap(df_cm_reg_log_filtered_sw, annot=True, annot_kws={\"size\": 12}, cbar=False, square=True, fmt=\"d\", cmap=\"Reds\")\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-08-23T13:05:44.313952Z","iopub.execute_input":"2024-08-23T13:05:44.318818Z","iopub.status.idle":"2024-08-23T13:05:44.438476Z","shell.execute_reply.started":"2024-08-23T13:05:44.318745Z","shell.execute_reply":"2024-08-23T13:05:44.437334Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Discussion of Removing Stop Words\n\nThe model's performance did not improve after removing stop words. There could be several reasons why this happened:\n\n- The dataset might not heavily rely on stop words for classification.\n- Removing stop words might not have reduced the feature space significantly enough to improve model performance.","metadata":{}},{"cell_type":"markdown","source":"### 2. Scaling\n\n- Afterwards, decided to use scaling, particularly min-max scaling, with Logistic Regression because it performs better when features are on a similar scale. Min-max scaling was chosen because the data distribution is not Gaussian (not normal).\n- If features are on different scales (e.g., one feature ranges from 0 to 1000 and another from 0 to 10), features with larger scales can dominate the model's learning process. Scaling ensures that all features are transformed to a similar scale, preventing this dominance and allowing the model to learn from each feature more uniformly.\n- Besides, scaling ensures that the optimization process converges more quickly and efficiently, leading to faster training times.","metadata":{}},{"cell_type":"code","source":"# Importing preprocessing module from sklearn\nfrom sklearn import preprocessing","metadata":{"execution":{"iopub.status.busy":"2024-08-23T13:05:44.439794Z","iopub.execute_input":"2024-08-23T13:05:44.440943Z","iopub.status.idle":"2024-08-23T13:05:44.446017Z","shell.execute_reply.started":"2024-08-23T13:05:44.440888Z","shell.execute_reply":"2024-08-23T13:05:44.444719Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Min-Max Scaler","metadata":{}},{"cell_type":"code","source":"# Initialize MinMaxScaler for scaling features to a specified range (default is [0, 1])\nmin_max_scaler = preprocessing.MinMaxScaler()","metadata":{"execution":{"iopub.status.busy":"2024-08-23T13:05:44.447514Z","iopub.execute_input":"2024-08-23T13:05:44.448179Z","iopub.status.idle":"2024-08-23T13:05:44.458659Z","shell.execute_reply.started":"2024-08-23T13:05:44.448132Z","shell.execute_reply":"2024-08-23T13:05:44.457186Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Fit and transform the training data using MinMaxScaler to scale features to [0, 1]\nX_train_minmax = min_max_scaler.fit_transform(X_train)\nX_train_minmax","metadata":{"execution":{"iopub.status.busy":"2024-08-23T13:05:44.460223Z","iopub.execute_input":"2024-08-23T13:05:44.461056Z","iopub.status.idle":"2024-08-23T13:05:44.690069Z","shell.execute_reply.started":"2024-08-23T13:05:44.461005Z","shell.execute_reply":"2024-08-23T13:05:44.688827Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Transform the test data using the MinMaxScaler fitted on X_train\nX_test_minmax = min_max_scaler.fit_transform(X_test)\nX_test_minmax","metadata":{"execution":{"iopub.status.busy":"2024-08-23T13:05:44.691535Z","iopub.execute_input":"2024-08-23T13:05:44.691904Z","iopub.status.idle":"2024-08-23T13:05:44.810866Z","shell.execute_reply.started":"2024-08-23T13:05:44.691869Z","shell.execute_reply":"2024-08-23T13:05:44.809684Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Apply Logistic Regression","metadata":{}},{"cell_type":"code","source":"# Initialize Logistic Regression with MinMax scaled data\nreg_log_minmax = LogisticRegression(random_state=42, max_iter=1000)\nreg_log_minmax.fit(X_train_minmax, y_train)","metadata":{"execution":{"iopub.status.busy":"2024-08-23T13:05:44.812124Z","iopub.execute_input":"2024-08-23T13:05:44.812481Z","iopub.status.idle":"2024-08-23T13:05:45.311963Z","shell.execute_reply.started":"2024-08-23T13:05:44.812447Z","shell.execute_reply":"2024-08-23T13:05:45.310803Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Predict using the logistic regression model with MinMax scaled test data\ny_pred_reg_log_minmax = reg_log_minmax.predict(X_test_minmax)","metadata":{"execution":{"iopub.status.busy":"2024-08-23T13:05:45.313931Z","iopub.execute_input":"2024-08-23T13:05:45.314780Z","iopub.status.idle":"2024-08-23T13:05:45.325603Z","shell.execute_reply.started":"2024-08-23T13:05:45.314723Z","shell.execute_reply":"2024-08-23T13:05:45.324138Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Print classification report to evaluate model performance\nprint(\"Classification report: \")\nprint(classification_report(y_test, y_pred_reg_log_minmax))","metadata":{"execution":{"iopub.status.busy":"2024-08-23T13:05:45.327660Z","iopub.execute_input":"2024-08-23T13:05:45.328735Z","iopub.status.idle":"2024-08-23T13:05:45.350593Z","shell.execute_reply.started":"2024-08-23T13:05:45.328678Z","shell.execute_reply":"2024-08-23T13:05:45.349452Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Compute and print confusion matrix to assess model performance\ncm_reg_log_minmax = confusion_matrix(y_test, y_pred_reg_log_minmax)\n\n# Create a DataFrame from confusion matrix for visualization\ndf_cm_reg_log_minmax = pd.DataFrame(cm_reg_log_minmax, columns=np.unique(y_test), index=np.unique(y_test))\n\n# Set the names for the DataFrame's index (rows) and columns\ndf_cm_reg_log_minmax.index.name = 'Actual'\ndf_cm_reg_log_minmax.columns.name = 'Predicted'\n\n# Create a new figure for the heatmap visualization\nplt.figure(figsize=(1.5, 1.5))\n\n# Generate the heatmap using Seaborn\nsb.heatmap(df_cm_reg_log_minmax, annot=True, annot_kws={\"size\": 12}, cbar=False, square=True, fmt=\"d\", cmap=\"Reds\")\n\n# Display the heatmap\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-08-23T13:05:45.352309Z","iopub.execute_input":"2024-08-23T13:05:45.353061Z","iopub.status.idle":"2024-08-23T13:05:45.496986Z","shell.execute_reply.started":"2024-08-23T13:05:45.353004Z","shell.execute_reply":"2024-08-23T13:05:45.495743Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Discussion of the Performance after Using Min-Max Scaling\n\n- Precision and recall for both classes (0 and 1) have improved in the current result. For class 0 (not spam), precision and recall increased from 0.98 to 0.99, indicating fewer false positives and better identification of actual not-spam emails. For class 1 (spam), precision and recall increased from 0.94 to 0.97, showing better performance in identifying spam emails correctly.\n- The F1-scores have also improved across both classes, reflecting a better balance between precision and recall. Class 0's F1-score increased from 0.98 to 0.99, and class 1's F1-score improved from 0.95 to 0.97. This indicates a more robust performance in classification after scaling.\n- Overall accuracy increased from 0.97 to 0.98. This means that the model is making correct predictions for 98% of the emails in the test set after scaling, compared to 97% previously.","metadata":{}},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"## F. Models Comparision","metadata":{}},{"cell_type":"code","source":"# Create figure for the heatmaps\nfig, axs = plt.subplots(1, 4, figsize=(20, 5))\n\n# Heatmap for Naive Bayes\nsb.heatmap(df_cm_nb, annot=True, annot_kws={\"size\": 20}, cbar=False, square=True, fmt=\"d\", cmap=\"Reds\", ax=axs[0])\naxs[0].set_title('Naive Bayes', fontsize=18)\naxs[0].set_xlabel('Predicted', fontsize=16)\naxs[0].set_ylabel('Actual', fontsize=16)\naxs[0].tick_params(axis='both', which='major', labelsize=16)\n\n# Heatmap for Logistic Regression\nsb.heatmap(df_cm_reg_log, annot=True, annot_kws={\"size\": 20}, cbar=False, square=True, fmt=\"d\", cmap=\"Blues\", ax=axs[1])\naxs[1].set_title('Logistic Regression', fontsize=18)\naxs[1].set_xlabel('Predicted', fontsize=16)\naxs[1].set_ylabel('Actual', fontsize=16)\naxs[1].tick_params(axis='both', which='major', labelsize=16)\n\n# Heatmap for Logistic Regression on Filtered Stopwords\nsb.heatmap(df_cm_reg_log_filtered_sw, annot=True, annot_kws={\"size\": 20}, cbar=False, square=True, fmt=\"d\", cmap=\"Greens\", ax=axs[2])\naxs[2].set_title('Logistic Regression (Filtered Stopwords)', fontsize=18)\naxs[2].set_xlabel('Predicted', fontsize=16)\naxs[2].set_ylabel('Actual', fontsize=16)\naxs[2].tick_params(axis='both', which='major', labelsize=16)\n\n# Heatmap for Logistic Regression on Min-Max Scaled Features\nsb.heatmap(df_cm_reg_log_minmax, annot=True, annot_kws={\"size\": 20}, cbar=False, square=True, fmt=\"d\", cmap=\"Purples\", ax=axs[3])\naxs[3].set_title('Logistic Regression (Min-Max Scaled)', fontsize=18)\naxs[3].set_xlabel('Predicted', fontsize=16)\naxs[3].set_ylabel('Actual', fontsize=16)\naxs[3].tick_params(axis='both', which='major', labelsize=16)\n\n# Adjust layout\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-08-23T13:05:45.498880Z","iopub.execute_input":"2024-08-23T13:05:45.499757Z","iopub.status.idle":"2024-08-23T13:05:46.350605Z","shell.execute_reply.started":"2024-08-23T13:05:45.499702Z","shell.execute_reply":"2024-08-23T13:05:46.349528Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- In conclusion, Min-Max scaling has effectively contributed to the improved performance of the logistic regression model by enhancing its ability to learn from the data, leading to better classification results for identifying spam and non-spam emails in our dataset.\n- The combination of applying Min-Max scaling and Logistic Regression archieved the highest performance.","metadata":{}},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"## G. Cross-Validation\n\n- Cross-validation is a technique used to evaluate the performance of a model by dividing the data into multiple subsets, training the model on some subsets, and testing it on the remaining subsets.\n- This process is repeated several times to ensure the model's effectiveness and to prevent overfitting.","metadata":{}},{"cell_type":"code","source":"# Import cross-validation score evaluation function\nfrom sklearn.model_selection import cross_val_score","metadata":{"execution":{"iopub.status.busy":"2024-08-23T13:05:46.351942Z","iopub.execute_input":"2024-08-23T13:05:46.352304Z","iopub.status.idle":"2024-08-23T13:05:46.358442Z","shell.execute_reply.started":"2024-08-23T13:05:46.352266Z","shell.execute_reply":"2024-08-23T13:05:46.357172Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Apply MinMax scaling to the feature matrix X\nX_minmax = min_max_scaler.fit_transform(X)\nX_minmax","metadata":{"execution":{"iopub.status.busy":"2024-08-23T13:05:46.359921Z","iopub.execute_input":"2024-08-23T13:05:46.360532Z","iopub.status.idle":"2024-08-23T13:05:46.619886Z","shell.execute_reply.started":"2024-08-23T13:05:46.360471Z","shell.execute_reply":"2024-08-23T13:05:46.618746Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a Logistic Regression model with specified parameters\nlog_reg = LogisticRegression(random_state=42, max_iter=1000)\n\n# Perform cross-validation on the MinMax scaled data X_minmax and target y\nreg_log_minmax_scores = cross_val_score(log_reg, X_minmax, y, cv=5, scoring='accuracy')\n\n# Print the mean accuracy of cross-validation scores for Logistic Regression with MinMax scaling\nprint(\"Logistic Regression Minmax CV Accuracy: \", reg_log_minmax_scores.mean())","metadata":{"execution":{"iopub.status.busy":"2024-08-23T13:05:46.621242Z","iopub.execute_input":"2024-08-23T13:05:46.621606Z","iopub.status.idle":"2024-08-23T13:05:49.387218Z","shell.execute_reply.started":"2024-08-23T13:05:46.621570Z","shell.execute_reply":"2024-08-23T13:05:49.386112Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Discussion on the Cross-Validation\n\n- The \"Logistic Regression Minmax CV Accuracy: 0.95417281043553\" represents the average accuracy of a Logistic Regression model trained on data that has been scaled using MinMax scaling, evaluated using 5-fold cross-validation.\n- This metric indicates that, on average, the model correctly predicts the class of emails (spam or not spam) about 95.4% of the time across different folds of the dataset.\n- This score provides a robust estimate of the model's performance and its ability to generalize to unseen data, accounting for variations in the training and validation subsets used in cross-validation.","metadata":{}},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"## H. Testing with External Dataset\n\n- Link of the dataset: https://www.kaggle.com/datasets/ozlerhakan/spam-or-not-spam-dataset\n- The dataset contains 2,500 non-spam emails and 500 spam emails.","metadata":{}},{"cell_type":"code","source":"# Retrieve all columns except the last one from the dataframe `df`\ncolumns = df.columns[:-1]\ncolumns","metadata":{"execution":{"iopub.status.busy":"2024-08-23T13:05:49.388608Z","iopub.execute_input":"2024-08-23T13:05:49.389293Z","iopub.status.idle":"2024-08-23T13:05:49.408022Z","shell.execute_reply.started":"2024-08-23T13:05:49.389233Z","shell.execute_reply":"2024-08-23T13:05:49.406815Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import re  # Import the re module for working with regular expressions\nfrom collections import Counter  # Import the Counter class from the collections module","metadata":{"execution":{"iopub.status.busy":"2024-08-23T13:05:49.414050Z","iopub.execute_input":"2024-08-23T13:05:49.415051Z","iopub.status.idle":"2024-08-23T13:05:49.420339Z","shell.execute_reply.started":"2024-08-23T13:05:49.414994Z","shell.execute_reply":"2024-08-23T13:05:49.419195Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Import External Data","metadata":{}},{"cell_type":"code","source":"# Read the CSV file \"spam_or_not_spam.csv\" to assume this is the new data\ndf_external = pd.read_csv(\"/kaggle/input/spam-or-not-spam-dataset/spam_or_not_spam.csv\")\ndf_external","metadata":{"execution":{"iopub.status.busy":"2024-08-23T13:05:49.424759Z","iopub.execute_input":"2024-08-23T13:05:49.425927Z","iopub.status.idle":"2024-08-23T13:05:49.586716Z","shell.execute_reply.started":"2024-08-23T13:05:49.425858Z","shell.execute_reply":"2024-08-23T13:05:49.585622Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Ensure all entries in the 'email' column are strings\ndf_external['email'] = df_external['email'].astype(str)","metadata":{"execution":{"iopub.status.busy":"2024-08-23T13:05:49.588060Z","iopub.execute_input":"2024-08-23T13:05:49.588564Z","iopub.status.idle":"2024-08-23T13:05:49.594507Z","shell.execute_reply.started":"2024-08-23T13:05:49.588521Z","shell.execute_reply":"2024-08-23T13:05:49.593164Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Data Preprocessing","metadata":{}},{"cell_type":"code","source":"# Define a function to check if the text contains only Latin characters\ndef contains_only_latin_characters(text):\n    return bool(re.match(r'^[a-zA-Z\\s]*$', text))\n\n# Drop rows that do not contain only Latin characters\ndf_external = df_external[df_external['email'].apply(contains_only_latin_characters)]\n\n# Reset the index of the DataFrame\ndf_external = df_external.reset_index(drop=True)\n\ndf_external","metadata":{"execution":{"iopub.status.busy":"2024-08-23T13:05:49.595887Z","iopub.execute_input":"2024-08-23T13:05:49.596287Z","iopub.status.idle":"2024-08-23T13:05:49.648943Z","shell.execute_reply.started":"2024-08-23T13:05:49.596250Z","shell.execute_reply":"2024-08-23T13:05:49.647599Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Feature Extraction","metadata":{}},{"cell_type":"code","source":"# Function to preprocess and tokenize text\ndef preprocess_text(text):  \n    text = re.sub(r'[^a-z\\s]', '', text.lower()) # Remove non-alphabetical characters and convert to lowercase\n    text = re.sub(r\"\\W\", \" \", text) # Replace anything other than letters, digits, or underscore character with a white space\n    text = re.sub(r'\\s+', \" \", text) # Remove extra white spaces\n    \n    # Tokenize the text\n    tokens = text.split()\n    return tokens\n\n# Initialize a list to store the word frequency data for each email\ndata_list = []\n\n# Process each email\nfor email in df_external[\"email\"]:\n    # Preprocess the text\n    tokens = preprocess_text(email)\n    # Count word frequencies\n    word_counts = Counter(tokens)\n    # Create a dictionary for the current email's word frequencies\n    data = {word: word_counts.get(word, 0) for word in columns}\n    data_list.append(data)\n\n# Create a DataFrame from the list of dictionaries\nX_test_external = pd.DataFrame(data_list)\n\nX_test_external","metadata":{"execution":{"iopub.status.busy":"2024-08-23T13:05:49.650231Z","iopub.execute_input":"2024-08-23T13:05:49.650612Z","iopub.status.idle":"2024-08-23T13:05:53.513552Z","shell.execute_reply.started":"2024-08-23T13:05:49.650577Z","shell.execute_reply":"2024-08-23T13:05:53.512460Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Extract the last column (assumed to be the target variable) from the DataFrame df_external\ny_test_external = df_external.iloc[:,-1] \ny_test_external","metadata":{"execution":{"iopub.status.busy":"2024-08-23T13:05:53.515129Z","iopub.execute_input":"2024-08-23T13:05:53.515612Z","iopub.status.idle":"2024-08-23T13:05:53.525768Z","shell.execute_reply.started":"2024-08-23T13:05:53.515560Z","shell.execute_reply":"2024-08-23T13:05:53.524580Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create countplot\nsb.countplot(x=y_test_external)\nplt.title('Countplot of y')\nplt.xlabel('y')\nplt.ylabel('Count')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-08-23T13:05:53.527282Z","iopub.execute_input":"2024-08-23T13:05:53.527698Z","iopub.status.idle":"2024-08-23T13:05:53.741651Z","shell.execute_reply.started":"2024-08-23T13:05:53.527661Z","shell.execute_reply":"2024-08-23T13:05:53.740672Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Transform the features in X_test_external using the fitted MinMaxScaler\nX_test_minmax_external = min_max_scaler.fit_transform(X_test_external)\nX_test_minmax_external","metadata":{"execution":{"iopub.status.busy":"2024-08-23T13:05:53.743093Z","iopub.execute_input":"2024-08-23T13:05:53.743450Z","iopub.status.idle":"2024-08-23T13:05:53.895571Z","shell.execute_reply.started":"2024-08-23T13:05:53.743415Z","shell.execute_reply":"2024-08-23T13:05:53.894430Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Predict using the logistic regression model with MinMax scaled test data\ny_pred_reg_log_minmax_external = reg_log_minmax.predict(X_test_minmax_external)","metadata":{"execution":{"iopub.status.busy":"2024-08-23T13:05:53.896825Z","iopub.execute_input":"2024-08-23T13:05:53.897157Z","iopub.status.idle":"2024-08-23T13:05:53.911816Z","shell.execute_reply.started":"2024-08-23T13:05:53.897124Z","shell.execute_reply":"2024-08-23T13:05:53.910530Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Print the classification report comparing y_test_external and y_pred_reg_log_minmax_external\nprint(\"Classification report: \")\nprint(classification_report(y_test_external, y_pred_reg_log_minmax_external))","metadata":{"execution":{"iopub.status.busy":"2024-08-23T13:05:53.913490Z","iopub.execute_input":"2024-08-23T13:05:53.914258Z","iopub.status.idle":"2024-08-23T13:05:53.937960Z","shell.execute_reply.started":"2024-08-23T13:05:53.914205Z","shell.execute_reply":"2024-08-23T13:05:53.936762Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Compute and print confusion matrix to assess model performance\ncm_reg_log_minmax_external = confusion_matrix(y_test_external, y_pred_reg_log_minmax_external)\n\n# Create a DataFrame from the confusion matrix for visualization\ndf_reg_log_minmax_external = pd.DataFrame(cm_reg_log_minmax_external, columns=np.unique(y_test), index=np.unique(y_test))\n\n# Set the names for the DataFrame's index (rows) and columns\ndf_reg_log_minmax_external.index.name = 'Actual'\ndf_reg_log_minmax_external.columns.name = 'Predicted'\n\n# Create a new figure for the heatmap visualization\nplt.figure(figsize=(1.5, 1.5))\n\n# Generate the heatmap using Seaborn\nsb.heatmap(df_reg_log_minmax_external, annot=True, annot_kws={\"size\": 12}, cbar=False, square=True, fmt=\"d\", cmap=\"Reds\")\n\n# Display the heatmap\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-08-23T13:05:53.939597Z","iopub.execute_input":"2024-08-23T13:05:53.940463Z","iopub.status.idle":"2024-08-23T13:05:54.081486Z","shell.execute_reply.started":"2024-08-23T13:05:53.940407Z","shell.execute_reply":"2024-08-23T13:05:54.080288Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Discussion on the Result of Testing on the External Dataset\n\n- Although the performance drops on the external dataset, the model still manages to identify a substantial portion of spam emails (recall of 0.75 for spam). This suggests that the model retains some generalization capabilities, which is promising for handling real-world data.\n- The model maintains a high precision for not spam emails (0.91) in the external dataset, meaning that most emails predicted as not spam are indeed not spam. This is important for user trust, as it reduces the chances of important emails being incorrectly classified as spam.\n-  To improve performance on new incoming emails, consider enhancing the training process with diverse data, better handling of class imbalance, and further model tuning.","metadata":{}},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"## I. Findings and Insights","metadata":{}},{"cell_type":"markdown","source":"- Overall, the dataset consists of 5172 emails with features derived from counts of the 3000 most common words, creating a high-dimensional and sparse feature space. Exploratory Data Analysis revealed significant variation in feature values, with high means for common words and a wide range of values, yet no missing data was present. The label distribution is notably imbalanced, with a higher number of non-spam emails than spam, which can impact model performance by introducing bias towards the majority class.\n\n- Regarding model performance, Multinomial Naive Bayes was effective for text classification but showed a need to reduce false positives in spam detection. Logistic Regression outperformed Naive Bayes across several metrics, including accuracy (0.97 vs. 0.95), precision for spam detection (0.94 vs. 0.89), recall, and F1-score. By conducting feature engineering, removing stop words did not improve model performance, possibly due to its limited impact on the feature space. However, applying Min-Max scaling led to enhanced performance, with increased precision, recall, and F1-scores for both classes, and an overall accuracy improvement from 0.97 to 0.98.\n\n- Cross-validation results showed that Logistic Regression with Min-Max scaling achieved an average accuracy of 95.4% across 5 folds, indicating strong generalization. Despite a drop in performance on the external dataset (0.7 for the accuracy), the model maintained high precision for non-spam emails (0.91) and good recall for spam (0.75), suggesting it retains some generalization capabilities. Future improvements could focus on incorporating more diverse training data and addressing class imbalance more effectively.\n\n- Challenges included the feature independence assumption in Naive Bayes, which might not capture all the complexities of the data. Applied Logistic Regression to address this issue. While Min-Max scaling improved the performance of Logistic Regression, further exploration of feature engineering techniques could provide additional benefits. Another challenge was managing class imbalance to avoid bias towards non-spam emails. Attempted both under-sampling and over-sampling, but both approaches yielded worse results with the external dataset. Therefore, may consider alternative methods such as advanced resampling techniques or incorporating class weights for further improvement.","metadata":{}}]}